{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fc41c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9aa4e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Softmax:\n",
    "    def __call__(self, x):\n",
    "        exps = np.exp(x)\n",
    "        self._softmax = exps / np.sum(exps)\n",
    "        return self._softmax\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ddfc336",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sigmoid:\n",
    "    def __call__(self, x):\n",
    "        exps = np.exp(x)\n",
    "        self._sigmoid = exps / (1 + exps)\n",
    "        return self._sigmoid\n",
    "\n",
    "    def derivative(self):\n",
    "        return self._sigmoid * (1-self._sigmoid)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a870c2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def softmax(arr):\n",
    "#     exps = np.exp(arr)\n",
    "#     return exps / np.sum(exps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1da33954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def sigmoid(arr):\n",
    "#     exps = np.exp(arr)\n",
    "#     return exps / (1 + exps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b0c9ee94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mseloss(preds, labels):\n",
    "    matrix = np.square(preds - labels)\n",
    "    return np.mean(matrix), matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78e1f0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MSELoss:\n",
    "    def __call__(self, preds, labels):\n",
    "        self._loss = np.square(preds - labels)\n",
    "        return np.mean(self._loss)\n",
    "    \n",
    "    def derivative(self):\n",
    "        return np.sqrt(self._loss) * (-1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ba48c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y = w*x + b \n",
    "#dy/dw =  x\n",
    "#dy/db = 1\n",
    "#loss = sum(out-y)**2 / len\n",
    "#dloss/dy = 1/2 * sum(out-y) * (-1) * len\n",
    "#dloss/dw = dloss/dy * dy/dw = -(sum(out-y)* len) /2 * x = -1 * root(loss) /2 * x\n",
    "#dloss/db = dloss/dy * dy/db = -sum(out-y) * len /2 * 1 = -1 * root(loss) / 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "896c7a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[0,0,0], [10,10,10], [2,0,0]]) \n",
    "y = np.array([[0],[5],[3]])\n",
    "w = np.array([[0,0,0], [0,0,0], [0,0,0]])\n",
    "b =  np.array([[0],[0],[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "207972be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PReLU:\n",
    "    def __init__(self, a=0.25):\n",
    "        self.a = a\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        zeros = np.zeros(x.shape)\n",
    "        self._z = np.max([zeros, x], axis = 0) + self.a * np.min([zeros, x], axis = 0) \n",
    "        return self._z\n",
    "    \n",
    "    def derivative(self):\n",
    "        x, y = self._z.shape\n",
    "        zeros = np.zeros((x,y))\n",
    "        for i in range(x):\n",
    "            for j in range(y):\n",
    "                if self._z[i][j] >0:\n",
    "                    zeros[i][j] = 1\n",
    "                elif self._z[i][j] <0:\n",
    "                    zeros[i][j] =  -self.a\n",
    "        return zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f345a4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def PReLU(x, a = 0.25):\n",
    "#     zeros = np.zeros(x.shape)\n",
    "#     return np.max([zeros, x], axis = 0) + a * np.min([zeros, x], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e97c7836",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backpropagation(x, w, b, y, loss, learning_rate=1e-3):\n",
    "    dy_dw = x #shape : (n, in_size)\n",
    "    dy_db = 1 \n",
    "    dloss_dy = np.sqrt(loss) * (-1/2) #shape : (n, out_size)\n",
    "    dloss_dw = np.matmul(np.transpose(dy_dw),dloss_dy)#shape : (in_size, out_size)\n",
    "    dloss_db = dloss_dy* dy_db\n",
    "    w = w + learning_rate * dloss_dw\n",
    "    b = b + learning_rate * dloss_db \n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ad30c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이전 :  y = w*x + b \n",
    "#           loss = MSELoss(y', y)\n",
    "\n",
    "# 이후 :  y = w*x + b\n",
    "#            z = act_fn(y)\n",
    "#           loss = MSELoss(y', z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89e6222a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backpropagation_with_actfn(x, w, b, z, dz_dy,learning_rate=1e-3):\n",
    "    #dz_dy shape :  n, out_size\n",
    "        \n",
    "    dy_dw = x #shape : n, in_size\n",
    "    dy_db = 1 \n",
    "    dz_dw = np.matmul(np.transpose(dy_dw), dz_dy) #dz_dy * dy_dw , shape : in_size, out_size\n",
    "    dz_db = dz_dy * dy_db #dz_dy * dy_db , shape n, out_size\n",
    "    w = w + learning_rate * dz_dw\n",
    "    b = b + learning_rate * dz_db \n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d9209f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear:\n",
    "    def __init__(self, in_size, out_size, epochs = 10, learning_rate = 1e-3):\n",
    "        self.epochs = epochs\n",
    "        self.learning_rate = learning_rate\n",
    "        self.in_size = in_size\n",
    "        self.out_size = out_size\n",
    "        self._initialize_weights()\n",
    "        self.act_fn = Sigmoid()\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        self.weight = np.random.rand(self.in_size, self.out_size)\n",
    "        self.bias = np.random.rand(self.out_size)\n",
    "        \n",
    "    def _forward(self, x):\n",
    "        out = np.matmul(x, self.weight) + self.bias\n",
    "        out = self.act_fn(out)\n",
    "        return out\n",
    "    \n",
    "    def train(self, x, y):\n",
    "        for e in range(self.epochs):\n",
    "            out = self._forward(x)\n",
    "            loss, loss_matrix = mseloss(out, y)\n",
    "            self.weight, self.bias = backpropagation_with_actfn(x, self.weight, self.bias, y, self.act_fn.derivative(), learning_rate = self.learning_rate)\n",
    "            print(f'{e+1}번째 epoch의 loss는 {loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b63b1ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.random.rand(1, 4)\n",
    "x = np.array([[0,1,0,1], [10,10,10,2], [0,0,0,3]]) \n",
    "y = np.array([[0],[1],[0]])\n",
    "b = np.random.rand(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b4fcb59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = Linear(x.shape[-1], y.shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "01c2ae78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1번째 epoch의 loss는 0.29056577915144804\n",
      "2번째 epoch의 loss는 0.29098802998841194\n",
      "3번째 epoch의 loss는 0.2914101107585081\n",
      "4번째 epoch의 loss는 0.2918320183292913\n",
      "5번째 epoch의 loss는 0.2922537495808795\n",
      "6번째 epoch의 loss는 0.2926753014060545\n",
      "7번째 epoch의 loss는 0.2930966707103592\n",
      "8번째 epoch의 loss는 0.29351785441219524\n",
      "9번째 epoch의 loss는 0.2939388494429187\n",
      "10번째 epoch의 loss는 0.29435965274693315\n"
     ]
    }
   ],
   "source": [
    "linear.train(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "879f0b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewLinear:\n",
    "    def __init__(self, in_size, out_size, act_fn = 'PReLU'):\n",
    "        self.in_size = in_size\n",
    "        self.out_size = out_size\n",
    "        \n",
    "        if act_fn == 'PReLU':\n",
    "            self.act_fn = PReLU()\n",
    "        elif act_fn == 'Softmax':\n",
    "            self.act_fn = Softmax()\n",
    "        elif act_fn == 'Sigmoid':\n",
    "            self.act_fn = Sigmoid()\n",
    "        \n",
    "        self._initialize_weights()\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        self.weight = np.random.rand(self.in_size, self.out_size)\n",
    "        self.bias = np.random.rand(self.out_size)\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        out = np.matmul(x,self.weight) + self.bias\n",
    "        out = self.act_fn(out)\n",
    "        return out\n",
    "    \n",
    "    def update(self, x, z, learning_rate):\n",
    "        dz_dy = self.act_fn.derivative()\n",
    "        self.weight, self.bias = backpropagation_with_actfn(x, self.weight, self.bias, z, dz_dy, learning_rate = learning_rate)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602bde0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#linear = NewLinear(x.shape[-1], y.shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a9dca6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Train:\n",
    "    def __init__(self, x, y, n_layers =3, n_node = 32, epochs=10, learning_rate=1e-3):\n",
    "        self.epochs = epochs\n",
    "        self.learning_rate = learning_rate\n",
    "        self.layers = []\n",
    "        self.loss_fcn = MSELoss()\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        for i in range(n_layers):\n",
    "            act_fn = 'PReLU'\n",
    "            in_shape = n_node\n",
    "            out_shape = n_node\n",
    "            if i == 0: #첫번째 레이어\n",
    "                in_shape = x.shape[-1]\n",
    "\n",
    "            if i == n_layers-1: #마지막 레이어\n",
    "                out_shape = y.shape[-1]\n",
    "                act_fn = 'Sigmoid'\n",
    "            self.layers.append(NewLinear(in_shape, out_shape, act_fn))\n",
    "            \n",
    "        self._train(x, y)\n",
    "        \n",
    "    def _forward(self, x):\n",
    "        outs = []\n",
    "        out = x\n",
    "        for layer in self.layers:\n",
    "            out = layer(out)\n",
    "            outs.append(out)\n",
    "        return outs, out #outs에는 지금까지 layer들의 출력값이 담겨있다. \n",
    "    \n",
    "    def _backpropagation(self, x, outs):\n",
    "        last = x\n",
    "        zipped = list(zip(self.layers, outs))\n",
    "        for i, (layer, out) in enumerate(zipped):\n",
    "            if i == self.n_layers - 1: #마지막 레이어일 때\n",
    "                out = out * self.loss_fcn.derivative()\n",
    "            layer.update(last, out, self.learning_rate)\n",
    "            last = out\n",
    "        \n",
    "    def _train(self, x, y):\n",
    "        for e in range(self.epochs):\n",
    "            outs, out = self._forward(x)\n",
    "            loss = self.loss_fcn(out, y)\n",
    "            outs.append(loss) #각 layer의 역전파를 위해 쓰일 배열이다. \n",
    "            self._backpropagation(x, outs)\n",
    "        \n",
    "            print(f'{e+1}번째 epoch의 loss는 {loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dc8b1a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1번째 epoch의 loss는 0.4342514791432084\n",
      "2번째 epoch의 loss는 0.43449342348115433\n",
      "3번째 epoch의 loss는 0.4347349468984185\n",
      "4번째 epoch의 loss는 0.43497605009271473\n",
      "5번째 epoch의 loss는 0.4352167337624741\n",
      "6번째 epoch의 loss는 0.4354569986068239\n",
      "7번째 epoch의 loss는 0.43569684532556624\n",
      "8번째 epoch의 loss는 0.43593627461915646\n",
      "9번째 epoch의 loss는 0.43617528718868287\n",
      "10번째 epoch의 loss는 0.43641388373584594\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.Train at 0x7fc970852070>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train(x, y,n_layers=1, n_node=32)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
